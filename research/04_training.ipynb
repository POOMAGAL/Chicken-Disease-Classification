{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4fec221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jupyter\n",
      "  Using cached jupyter-1.1.1-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting notebook (from jupyter)\n",
      "  Using cached notebook-7.4.7-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting jupyter-console (from jupyter)\n",
      "  Using cached jupyter_console-6.6.3-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting nbconvert (from jupyter)\n",
      "  Using cached nbconvert-7.16.6-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: ipykernel in c:\\users\\sabari b\\.conda\\envs\\chicken\\lib\\site-packages (from jupyter) (6.29.5)\n",
      "Collecting ipywidgets (from jupyter)\n",
      "  Using cached ipywidgets-8.1.8-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting jupyterlab (from jupyter)\n",
      "  Using cached jupyterlab-4.3.8-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\sabari b\\.conda\\envs\\chicken\\lib\\site-packages (from ipykernel->jupyter) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\sabari b\\.conda\\envs\\chicken\\lib\\site-packages (from ipykernel->jupyter) (1.8.5)\n",
      "Requirement already satisfied: ipython>=7.23.1 in c:\\users\\sabari b\\.conda\\envs\\chicken\\lib\\site-packages (from ipykernel->jupyter) (8.12.2)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\sabari b\\.conda\\envs\\chicken\\lib\\site-packages (from ipykernel->jupyter) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\sabari b\\.conda\\envs\\chicken\\lib\\site-packages (from ipykernel->jupyter) (5.8.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\sabari b\\.conda\\envs\\chicken\\lib\\site-packages (from ipykernel->jupyter) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\sabari b\\.conda\\envs\\chicken\\lib\\site-packages (from ipykernel->jupyter) (1.6.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\sabari b\\.conda\\envs\\chicken\\lib\\site-packages (from ipykernel->jupyter) (25.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\sabari b\\.conda\\envs\\chicken\\lib\\site-packages (from ipykernel->jupyter) (6.0.0)\n",
      "Requirement already satisfied: pyzmq>=24 in c:\\users\\sabari b\\.conda\\envs\\chicken\\lib\\site-packages (from ipykernel->jupyter) (26.2.0)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\sabari b\\.conda\\envs\\chicken\\lib\\site-packages (from ipykernel->jupyter) (6.4.1)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in c:\\users\\sabari b\\.conda\\envs\\chicken\\lib\\site-packages (from ipykernel->jupyter) (5.14.3)\n",
      "Collecting widgetsnbextension~=4.0.14 (from ipywidgets->jupyter)\n",
      "  Using cached widgetsnbextension-4.0.15-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab_widgets~=3.0.15 (from ipywidgets->jupyter)\n",
      "  Using cached jupyterlab_widgets-3.0.16-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.30 in c:\\users\\sabari b\\.conda\\envs\\chicken\\lib\\site-packages (from jupyter-console->jupyter) (3.0.48)\n",
      "Requirement already satisfied: pygments in c:\\users\\sabari b\\.conda\\envs\\chicken\\lib\\site-packages (from jupyter-console->jupyter) (2.18.0)\n",
      "Collecting async-lru>=1.0.0 (from jupyterlab->jupyter)\n",
      "  Using cached async_lru-2.0.4-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting httpx>=0.25.0 (from jupyterlab->jupyter)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.3 in c:\\users\\sabari b\\.conda\\envs\\chicken\\lib\\site-packages (from jupyterlab->jupyter) (8.5.0)\n",
      "Requirement already satisfied: importlib-resources>=1.4 in c:\\users\\sabari b\\.conda\\envs\\chicken\\lib\\site-packages (from jupyterlab->jupyter) (6.4.5)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in c:\\users\\sabari b\\.conda\\envs\\chicken\\lib\\site-packages (from jupyterlab->jupyter) (3.1.6)\n",
      "Collecting jupyter-lsp>=2.0.0 (from jupyterlab->jupyter)\n",
      "  Using cached jupyter_lsp-2.3.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting jupyter-server<3,>=2.4.0 (from jupyterlab->jupyter)\n",
      "  Using cached jupyter_server-2.14.2-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting jupyterlab-server<3,>=2.27.1 (from jupyterlab->jupyter)\n",
      "  Using cached jupyterlab_server-2.28.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting notebook-shim>=0.2 (from jupyterlab->jupyter)\n",
      "  Using cached notebook_shim-0.2.4-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: setuptools>=41.1.0 in c:\\users\\sabari b\\.conda\\envs\\chicken\\lib\\site-packages (from jupyterlab->jupyter) (75.3.2)\n",
      "Collecting tomli>=1.2.2 (from jupyterlab->jupyter)\n",
      "  Using cached tomli-2.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting beautifulsoup4 (from nbconvert->jupyter)\n",
      "  Using cached beautifulsoup4-4.14.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting bleach!=5.0.0 (from bleach[css]!=5.0.0->nbconvert->jupyter)\n",
      "  Using cached bleach-6.1.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting defusedxml (from nbconvert->jupyter)\n",
      "  Using cached defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Collecting jupyterlab-pygments (from nbconvert->jupyter)\n",
      "  Using cached jupyterlab_pygments-0.3.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: markupsafe>=2.0 in c:\\users\\sabari b\\.conda\\envs\\chicken\\lib\\site-packages (from nbconvert->jupyter) (2.1.5)\n",
      "Collecting mistune<4,>=2.0.3 (from nbconvert->jupyter)\n",
      "  Using cached mistune-3.1.4-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting nbclient>=0.5.0 (from nbconvert->jupyter)\n",
      "  Using cached nbclient-0.10.1-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting nbformat>=5.7 (from nbconvert->jupyter)\n",
      "  Using cached nbformat-5.10.4-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting pandocfilters>=1.4.1 (from nbconvert->jupyter)\n",
      "  Using cached pandocfilters-1.5.1-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "INFO: pip is looking at multiple versions of notebook to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting notebook (from jupyter)\n",
      "  Using cached notebook-7.4.6-py3-none-any.whl.metadata (10 kB)\n",
      "  Using cached notebook-7.4.5-py3-none-any.whl.metadata (10 kB)\n",
      "  Using cached notebook-7.4.4-py3-none-any.whl.metadata (10 kB)\n",
      "  Using cached notebook-7.4.3-py3-none-any.whl.metadata (10 kB)\n",
      "  Using cached notebook-7.4.2-py3-none-any.whl.metadata (10 kB)\n",
      "  Using cached notebook-7.4.1-py3-none-any.whl.metadata (10 kB)\n",
      "  Using cached notebook-7.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "INFO: pip is still looking at multiple versions of notebook to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached notebook-7.3.3-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\sabari b\\.conda\\envs\\chicken\\lib\\site-packages (from async-lru>=1.0.0->jupyterlab->jupyter) (4.12.2)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\sabari b\\.conda\\envs\\chicken\\lib\\site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter) (1.16.0)\n",
      "Collecting webencodings (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter)\n",
      "  Using cached webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting tinycss2<1.3,>=1.1.0 (from bleach[css]!=5.0.0->nbconvert->jupyter)\n",
      "  Using cached tinycss2-1.2.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting anyio (from httpx>=0.25.0->jupyterlab->jupyter)\n",
      "  Using cached anyio-4.5.2-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: certifi in c:\\users\\sabari b\\.conda\\envs\\chicken\\lib\\site-packages (from httpx>=0.25.0->jupyterlab->jupyter) (2025.11.12)\n",
      "Collecting httpcore==1.* (from httpx>=0.25.0->jupyterlab->jupyter)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: idna in c:\\users\\sabari b\\.conda\\envs\\chicken\\lib\\site-packages (from httpx>=0.25.0->jupyterlab->jupyter) (3.11)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx>=0.25.0->jupyterlab->jupyter)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\sabari b\\.conda\\envs\\chicken\\lib\\site-packages (from importlib-metadata>=4.8.3->jupyterlab->jupyter) (3.20.2)\n",
      "Requirement already satisfied: backcall in c:\\users\\sabari b\\.conda\\envs\\chicken\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.2.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\sabari b\\.conda\\envs\\chicken\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\sabari b\\.conda\\envs\\chicken\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.19.1)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\sabari b\\.conda\\envs\\chicken\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.7.5)\n",
      "Requirement already satisfied: stack-data in c:\\users\\sabari b\\.conda\\envs\\chicken\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.6.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\sabari b\\.conda\\envs\\chicken\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sabari b\\.conda\\envs\\chicken\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter) (2.9.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\sabari b\\.conda\\envs\\chicken\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (3.11.0)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\sabari b\\.conda\\envs\\chicken\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (306)\n",
      "Collecting argon2-cffi>=21.1 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached argon2_cffi-25.1.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting jupyter-events>=0.9.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached jupyter_events-0.10.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting jupyter-server-terminals>=0.4.4 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting overrides>=5.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting prometheus-client>=0.9 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached prometheus_client-0.21.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting pywinpty>=2.0.1 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached pywinpty-2.0.14.tar.gz (27 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × pip subprocess to install backend dependencies did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [2 lines of output]\n",
      "      ERROR: Could not find a version that satisfies the requirement puccinialin (from versions: none)\n",
      "      ERROR: No matching distribution found for puccinialin\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "× pip subprocess to install backend dependencies did not run successfully.\n",
      "│ exit code: 1\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    }
   ],
   "source": [
    "pip install jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6613f42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3ce8ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Poomagal\\\\Tech\\\\python_work\\\\Learning\\\\Chicken-Disease-Classification\\\\research'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05f19e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef971378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Poomagal\\\\Tech\\\\python_work\\\\Learning\\\\Chicken-Disease-Classification'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d558db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class TrainingConfig:\n",
    "    root_dir: Path\n",
    "    trained_model_path: Path\n",
    "    updated_base_model_path: Path\n",
    "    training_data: Path\n",
    "    params_epochs: int\n",
    "    params_batch_size: int\n",
    "    params_is_augmentation: bool\n",
    "    params_image_size: list\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class PrepareCallbacksConfig:\n",
    "    root_dir: Path\n",
    "    tensorboard_root_log_dir: Path\n",
    "    checkpoint_model_filepath: Path\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40bfe26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnnClassifier.constants import *\n",
    "from cnnClassifier.utils.common import read_yaml, create_directories\n",
    "import tensorflow as tf\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "\n",
    "    def get_prepare_callback_config(self) -> PrepareCallbacksConfig:\n",
    "        config = self.config.prepare_callbacks\n",
    "        model_ckpt_dir = os.path.dirname(config.checkpoint_model_filepath)\n",
    "        create_directories([\n",
    "            Path(model_ckpt_dir),\n",
    "            Path(config.tensorboard_root_log_dir)\n",
    "        ])\n",
    "\n",
    "        prepare_callback_config = PrepareCallbacksConfig(\n",
    "            root_dir=Path(config.root_dir),\n",
    "            tensorboard_root_log_dir=Path(config.tensorboard_root_log_dir),\n",
    "            checkpoint_model_filepath=Path(config.checkpoint_model_filepath)\n",
    "        )\n",
    "\n",
    "        return prepare_callback_config\n",
    "\n",
    "\n",
    "\n",
    "    def get_training_config(self) -> TrainingConfig:\n",
    "        training = self.config.training\n",
    "        prepare_base_model = self.config.prepare_base_model\n",
    "        params = self.params\n",
    "        training_data = os.path.join(self.config.data_ingestion.unzip_dir, \"Chicken-fecal-images\")\n",
    "        create_directories([\n",
    "            Path(training.root_dir)\n",
    "        ])\n",
    "\n",
    "        training_config = TrainingConfig(\n",
    "            root_dir=Path(training.root_dir),\n",
    "            trained_model_path=Path(training.trained_model_path),\n",
    "            updated_base_model_path=Path(prepare_base_model.updated_base_model_path),\n",
    "            training_data=Path(training_data),\n",
    "            params_epochs=params.EPOCHS,\n",
    "            params_batch_size=params.BATCH_SIZE,\n",
    "            params_is_augmentation=params.AUGMENTATION,\n",
    "            params_image_size=params.IMAGE_SIZE\n",
    "        )\n",
    "\n",
    "        return training_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3def242e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import os\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# Define the missing config class\n",
    "# -------------------------------------------------------\n",
    "class PrepareCallbacksConfig:\n",
    "    def __init__(\n",
    "        self,\n",
    "        root_dir,\n",
    "        tensorboard_root_log_dir,\n",
    "        checkpoint_model_filepath\n",
    "    ):\n",
    "        self.root_dir = str(root_dir)\n",
    "        self.tensorboard_root_log_dir = str(tensorboard_root_log_dir)\n",
    "        self.checkpoint_model_filepath = str(checkpoint_model_filepath)\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# Main Callback Builder Class\n",
    "# -------------------------------------------------------\n",
    "class PrepareCallback:\n",
    "    def __init__(self, config: PrepareCallbacksConfig):\n",
    "        self.config = config\n",
    "\n",
    "    @property\n",
    "    def _create_tb_callbacks(self):\n",
    "        timestamp = time.strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "        tb_running_log_dir = os.path.join(\n",
    "            str(self.config.tensorboard_root_log_dir),\n",
    "            f\"tb_logs_at_{timestamp}\",\n",
    "        )\n",
    "        return tf.keras.callbacks.TensorBoard(log_dir=tb_running_log_dir)\n",
    "\n",
    "    @property\n",
    "    def _create_ckpt_callbacks(self):\n",
    "        return tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath=str(self.config.checkpoint_model_filepath),   # FIX HERE\n",
    "            save_best_only=True\n",
    "        )\n",
    "\n",
    "    def get_tb_ckpt_callbacks(self):\n",
    "        return [\n",
    "            self._create_tb_callbacks,\n",
    "            self._create_ckpt_callbacks\n",
    "        ]\n",
    "\n",
    "\n",
    "# class PrepareCallback:\n",
    "#     def __init__(self, config: PrepareCallbacksConfig):\n",
    "#         self.config = config\n",
    "\n",
    "#     @property\n",
    "#     def _create_tb_callbacks(self):\n",
    "#         timestamp = time.strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "#         tb_running_log_dir = os.path.join(\n",
    "#             self.config.tensorboard_root_log_dir,\n",
    "#             f\"tb_logs_at_{timestamp}\",\n",
    "#         )\n",
    "#         return tf.keras.callbacks.TensorBoard(log_dir=tb_running_log_dir)\n",
    "\n",
    "\n",
    "#     @property\n",
    "#     def _create_ckpt_callbacks(self):\n",
    "#         return tf.keras.callbacks.ModelCheckpoint(\n",
    "#             filepath=self.config.checkpoint_model_filepath,\n",
    "#             save_best_only=True\n",
    "#         )\n",
    "\n",
    "\n",
    "#     def get_tb_ckpt_callbacks(self):\n",
    "#         return [\n",
    "#             self._create_tb_callbacks,\n",
    "#             self._create_ckpt_callbacks\n",
    "#         ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fc4f90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request as request\n",
    "from zipfile import ZipFile\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "\n",
    "class Training:\n",
    "    def __init__(self, config: TrainingConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def get_base_model(self):\n",
    "        self.model = tf.keras.models.load_model(\n",
    "            self.config.updated_base_model_path\n",
    "        )\n",
    "\n",
    "    def train_valid_generator(self):\n",
    "\n",
    "        datagenerator_kwargs = dict(\n",
    "            rescale = 1./255,\n",
    "            validation_split=0.20\n",
    "        )\n",
    "\n",
    "        dataflow_kwargs = dict(\n",
    "            target_size=self.config.params_image_size[:-1],\n",
    "            batch_size=self.config.params_batch_size,\n",
    "            interpolation=\"bilinear\"\n",
    "        )\n",
    "\n",
    "        valid_datagenerator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "            **datagenerator_kwargs\n",
    "        )\n",
    "        self.valid_generator = valid_datagenerator.flow_from_directory(\n",
    "            directory=self.config.training_data,\n",
    "            subset=\"validation\",\n",
    "            shuffle=False,\n",
    "            **dataflow_kwargs\n",
    "        )\n",
    "\n",
    "        if self.config.params_is_augmentation:\n",
    "            train_datagenerator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "                rotation_range=40,\n",
    "                horizontal_flip=True,\n",
    "                width_shift_range=0.2,\n",
    "                height_shift_range=0.2,\n",
    "                shear_range=0.2,\n",
    "                zoom_range=0.2,\n",
    "                **datagenerator_kwargs\n",
    "            )\n",
    "        else:\n",
    "            train_datagenerator = valid_datagenerator\n",
    "\n",
    "        self.train_generator = train_datagenerator.flow_from_directory(\n",
    "            directory=self.config.training_data,\n",
    "            subset=\"training\",\n",
    "            shuffle=True,\n",
    "            **dataflow_kwargs\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def save_model(path: Path, model: tf.keras.Model):\n",
    "        model.save(path)\n",
    "\n",
    "    def train(self, callback_list: list):\n",
    "        self.steps_per_epoch = self.train_generator.samples // self.train_generator.batch_size\n",
    "        self.validation_steps = self.valid_generator.samples // self.valid_generator.batch_size\n",
    "\n",
    "        self.model.fit(\n",
    "            self.train_generator,\n",
    "            epochs=self.config.params_epochs,\n",
    "            steps_per_epoch=self.steps_per_epoch,\n",
    "            validation_steps=self.validation_steps,\n",
    "            validation_data=self.valid_generator,\n",
    "            callbacks=callback_list\n",
    "        )\n",
    "                \n",
    "        self.save_model(\n",
    "            path=self.config.trained_model_path,\n",
    "            model=self.model\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17b51384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-12-01 10:29:33,677: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2025-12-01 10:29:33,682: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2025-12-01 10:29:33,684: INFO: common: created directory at: artifacts]\n",
      "[2025-12-01 10:29:33,687: INFO: common: created directory at: artifacts\\prepare_callbacks\\checkpoint_dir]\n",
      "[2025-12-01 10:29:33,689: INFO: common: created directory at: artifacts\\prepare_callbacks\\tensorboard_log_dir]\n",
      "[2025-12-01 10:29:33,696: INFO: common: created directory at: artifacts\\training]\n",
      "Found 78 images belonging to 2 classes.\n",
      "Found 312 images belonging to 2 classes.\n",
      "19/19 [==============================] - 92s 5s/step - loss: 12.2889 - accuracy: 0.5338 - val_loss: 1.2923 - val_accuracy: 0.8281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sabari B\\.conda\\envs\\chicken\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    prepare_callbacks_config = config.get_prepare_callback_config()\n",
    "    prepare_callbacks = PrepareCallback(config=prepare_callbacks_config)\n",
    "    callback_list = prepare_callbacks.get_tb_ckpt_callbacks()\n",
    "\n",
    "    training_config = config.get_training_config()\n",
    "    training = Training(config=training_config)\n",
    "    training.get_base_model()\n",
    "    training.train_valid_generator()\n",
    "    training.train(\n",
    "        callback_list=callback_list\n",
    "    )\n",
    "\n",
    "except Exception as e:\n",
    "    raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233e8265",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chicken",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
